<!DOCTYPE html><html><head>
      <title>week2_confidence_aware_ledger_extraction</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/javascript">
          window.MathJax = ({"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"options":{},"loader":{}});
        </script>
        <script type="text/javascript" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" charset="UTF-8"></script>
        
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="confidence-aware-extraction-of-historical-ledger-records">Confidence-Aware Extraction of Historical Ledger Records</h1>
<h2 id="a-multimodal-pipeline-for-scanned-archival-documents">A Multimodal Pipeline for Scanned Archival Documents</h2>
<p><strong>Hamid Ostadi</strong> HaI Lab, Saïd Business School Week 2 Project Report</p>
<hr>
<h2 id="introduction">1. Introduction</h2>
<p>Historical financial ledgers constitute a rich but methodologically challenging source for economic and social research. While these documents often span centuries and contain highly structured financial information, they are typically preserved as scanned images, lack machine-readable text, and follow accounting conventions that differ substantially from modern standards. As a result, large-scale quantitative analysis of such archives has traditionally relied on labor-intensive manual transcription.</p>
<p>In the first week of this project, the focus was on developing an end-to-end pipeline for extracting structured transaction-level data from scanned ledger pages using multimodal large language models (LLMs). That work demonstrated that it is possible to recover semantically meaningful entries—such as descriptions, transaction types, and historical currency amounts—from image-only PDFs using a combination of OCR and schema-guided extraction. However, a key limitation of this initial pipeline was that correctness and reliability were assessed largely through manual inspection, with uncertainty remaining implicit rather than explicitly quantified.</p>
<p>The objective of the present work is to extend the previous pipeline by introducing a <strong>confidence-aware extraction framework</strong>. Instead of producing a single deterministic output per ledger entry, the system now attaches interpretable confidence scores at both <strong>the field and row levels</strong>. These scores quantify the model’s own certainty as well as the plausibility of extracted values under historically grounded accounting rules. By making uncertainty explicit and machine-readable, the pipeline is better suited for scalable archival analysis and selective human review.</p>
<hr>
<h2 id="data-and-challenges">2. Data and Challenges</h2>
<p>The dataset consists of 33 scanned ledger volumes covering the period from the early eighteenth to the late nineteenth century. Each volume is stored as a PDF file named by year (e.g., <code>1704.pdf</code>) and contains multiple pages of handwritten or early printed accounting records. None of the PDFs include embedded text; all content is stored as rasterized images.</p>
<p>Several challenges arise from the nature of this material:</p>
<ol type="1">
<li><strong>Image-only sources</strong>: Standard PDF text extraction tools fail because the documents contain no machine-readable text. Optical character recognition (OCR) is therefore a necessary first step.</li>
<li><strong>Historical currency systems</strong>: Monetary values are expressed in pounds, shillings, and pence (£/s/d), often with fractional pence (e.g., 1/4, 1/2, 3/4). These units follow constraints that differ from modern decimal systems and must be preserved rather than normalized.</li>
<li><strong>Layout variability</strong>: Ledger formats vary substantially across years and even within a single volume, including summary pages, sectional lists, and pages with totals interspersed among individual entries.</li>
<li><strong>No ground truth at scale</strong>: While small subsets can be manually transcribed, a full gold-standard dataset is unavailable, making explicit uncertainty estimation particularly valuable.</li>
</ol>
<hr>
<h2 id="methodology">3. Methodology</h2>
<h3 id="ocr-via-multimodal-language-models">3.1 OCR via Multimodal Language Models</h3>
<p>To address the lack of embedded text, each PDF page is first converted into a high-resolution image. These images are then passed to a vision-capable large language model, which is prompted to perform faithful line-by-line transcription of all visible text. The model is instructed explicitly not to summarize or interpret the content at this stage, but only to reproduce the textual structure of the page.</p>
<p>To ensure scalability and reproducibility, OCR outputs are cached to disk on a per-page basis. This design choice allows the pipeline to be restarted without reissuing OCR requests and separates the transcription stage cleanly from downstream semantic processing.</p>
<h3 id="unified-ledger-schema">3.2 Unified Ledger Schema</h3>
<p>All extracted transactions are mapped to a unified schema that is stable across documents and years. Each ledger row includes:</p>
<ul>
<li>Identifiers (<code>doc_id</code>, <code>page_id</code>, <code>row_id</code>)</li>
<li>A textual description of the entry</li>
<li>A transaction type (<code>Credit</code>, <code>Debit</code>, or <code>Unknown</code>)</li>
<li>Monetary fields (<code>pounds</code>, <code>shillings</code>, <code>pence</code>, and optional fractional pence)</li>
</ul>
<p>Crucially, historical currency units are preserved in their original form. No attempt is made to convert values into modern decimal representations at the extraction stage. This decision reflects the goal of maintaining historical fidelity and avoiding premature transformations that could obscure original accounting practices.</p>
<h3 id="confidence-scoring-framework">3.3 Confidence Scoring Framework</h3>
<p>The central contribution of this week’s work is the introduction of a multi-layer confidence scoring framework. For each extracted ledger row, three complementary forms of confidence are computed:</p>
<ol type="1">
<li><strong>Model-level confidence</strong>: The language model is prompted to report its confidence for each extracted field (e.g., description, transaction type, monetary values). These scores capture the model’s internal certainty given the OCR text and prompt constraints.</li>
<li><strong>Rule-based confidence</strong>: Independently of the model’s self-assessment, extracted rows are evaluated against simple but historically grounded rules. Examples include valid ranges for shillings and pence, the presence of a non-empty description, and the plausibility of monetary combinations.</li>
<li><strong>Final row confidence</strong>: A weighted aggregation of model-level and rule-based confidence produces a single interpretable score per row. This value is intended as a headline indicator for downstream filtering and review.</li>
</ol>
<p>By decomposing uncertainty into these layers, the system avoids treating confidence as a black-box scalar and instead provides diagnostic insight into why a particular extraction should be trusted or questioned.</p>
<hr>
<h2 id="full-corpus-application">4. Full-Corpus Application</h2>
<p>The confidence-aware extraction pipeline was applied to the full collection of scanned ledger volumes. In total, 33 yearly PDFs were processed, each containing multiple pages of image-only historical accounting records. The pipeline operated in batch mode, automatically iterating over all documents placed in the raw data directory and applying OCR, semantic classification, structured extraction, and confidence scoring to every page.</p>
<p>Across the corpus, each PDF was first decomposed into individual page images, which were then transcribed using a multimodal language model. To ensure computational efficiency and reproducibility, OCR outputs were cached at the page level. This design allows the extraction and confidence-scoring stages to be re-run without repeating the costly transcription step, making the pipeline robust to interruptions and iterative refinement.</p>
<p>The extracted outputs from all documents were consolidated into a single structured dataset. Two artifacts were produced:</p>
<ul>
<li><p>A row-level table containing all extracted ledger entries, including descriptions, transaction types, historical currency fields, and associated confidence scores.</p></li>
<li><p>A page-level metadata table summarizing the semantic classification of each page and its inferred financial structure.</p></li>
</ul>
<p>Both artifacts were exported into a single Excel workbook, with separate sheets for transaction-level data and page metadata. This consolidated output enables straightforward inspection, filtering, and downstream analysis using standard data analysis tools, while preserving traceability back to the original document year and page number.</p>
<h2 id="confidence-analysis">5. Confidence Analysis</h2>
<p>A central advantage of the proposed pipeline is that uncertainty is made explicit and quantifiable. Rather than relying on implicit trust in extracted values, each ledger entry is accompanied by interpretable confidence scores that reflect both model self-assessment and historically grounded validation rules.</p>
<p>Across the full corpus of <strong>4,815 extracted rows</strong>, row-level confidence scores exhibit a clear and interpretable distribution. The <strong>average row confidence is 0.85</strong>, with a <strong>median value of 0.95</strong>, indicating that a large share of extracted entries are assessed as highly reliable. At the same time, the presence of lower-confidence rows <strong>(minimum observed value 0.27)</strong> reflects genuine extraction difficulty arising from degraded scans, ambiguous handwriting, or irregular formatting.</p>
<p>The concentration of values near the upper end of the scale suggests that the pipeline performs consistently on well-structured ledger entries, while still providing meaningful differentiation in more challenging cases.</p>
<p>Qualitative inspection further supports this interpretation. High-confidence rows typically correspond to clearly legible entries with unambiguous monetary values, such as annual rents or standardized payments, where both OCR transcription and semantic parsing are straightforward. In contrast, lower-confidence rows tend to arise on pages with dense layouts, faded ink, partial totals, or non-standard annotations, where uncertainty is inherent even for human readers.</p>
<p>Crucially, the availability of explicit confidence scores enables selective human review. Rather than treating all extracted rows as equally reliable, researchers can prioritize inspection of low-confidence entries while accepting high-confidence rows with minimal intervention. This capability substantially reduces the manual burden associated with large archival datasets and aligns the extraction process with best practices in human–AI collaboration.</p>
<h2 id="discussion">6. Discussion</h2>
<p>The results of the full-corpus application highlight the value of making uncertainty explicit in large-scale archival extraction tasks. Rather than treating automated transcription and parsing as a binary success or failure, the proposed pipeline frames extraction quality as a graded outcome. This perspective is particularly well suited to historical data, where ambiguity, degradation, and non-standardized formats are inherent rather than exceptional.</p>
<p>A key advantage of the confidence-aware approach is its ability to separate different sources of uncertainty. Model-level confidence captures the language model’s own assessment given the OCR text and prompt constraints, while rule-based confidence reflects adherence to historically grounded accounting conventions. By keeping these components distinct before aggregation, the system avoids conflating model fluency with historical plausibility. This design choice improves interpretability and facilitates targeted debugging when extraction quality is low.</p>
<p>Compared to purely rule-based post-processing, which silently corrects or discards outputs, the present framework emphasizes transparency. Rules do not override the model’s output; instead, they contextualize it by signaling whether extracted values align with known constraints of the ledger system. This distinction is important for scholarly use, as it preserves the original model output while still enabling principled quality assessment.</p>
<p>The approach also complements related work on financial logic checks, such as consistency validation and total reconciliation. While such checks can further improve accuracy, embedding them within a confidence-scoring framework allows their influence to be quantified rather than applied deterministically. In this sense, confidence-aware scoring provides a unifying layer through which diverse validation strategies can be integrated.</p>
<p>More broadly, explicit confidence scoring supports a human–AI collaboration model that is well aligned with historical research practice. High-confidence entries can be incorporated directly into quantitative analyses, while low-confidence rows can be flagged for manual review or exclusion. This selective inspection paradigm offers substantial efficiency gains over exhaustive manual transcription while maintaining scholarly rigor.</p>
<h2 id="conclusion-and-future-work">7. Conclusion and Future Work</h2>
<p>This project set out to extend an existing multimodal ledger extraction pipeline by making uncertainty explicit and operational. Building on prior work that demonstrated schema-guided extraction from scanned historical documents, the present contribution introduces a confidence-aware framework that quantifies extraction reliability at both the field and row levels. Applied to a corpus of 33 scanned ledger volumes, the system successfully extracted 4,815 transaction-level entries while providing interpretable confidence scores that reflect both model self-assessment and historically grounded validation rules.</p>
<p>The results demonstrate that confidence-aware extraction offers a practical and scalable alternative to purely manual transcription or opaque automated pipelines. By exposing uncertainty rather than masking it, the approach supports selective human review and enables researchers to balance scale with rigor. In this sense, the pipeline functions not as a replacement for historical expertise, but as an assistive research instrument that prioritizes transparency and interpretability.</p>
<p>Several directions for future work follow naturally from this framework. First, additional financial logic checks—such as reconciliation of page-level totals or cross-page consistency validation—could be incorporated as further contributors to the confidence score. Second, limited human-in-the-loop validation could be used to calibrate confidence thresholds and assess empirical accuracy on selected subsets of the data. Finally, the extracted and confidence-annotated dataset opens the door to substantive historical analysis, including longitudinal studies of rents, payments, and administrative practices across centuries.</p>
<p>Overall, this work demonstrates that large language models, when combined with explicit uncertainty modeling and domain-aware validation, can be deployed responsibly in archival research settings. The confidence-aware pipeline developed here provides a foundation for scalable, transparent, and methodologically sound analysis of historical financial records.</p>

      </div>
      <div class="md-sidebar-toc">
<div class="md-toc">
<details style="padding:0;;padding-left:0px;" open="">
        <summary class="md-toc-link-wrapper">
          <a href="#confidence-aware-extraction-of-historical-ledger-records" class="md-toc-link"><p>Confidence-Aware Extraction of Historical Ledger Records</p>
</a>
          </summary>
        <div>
          <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#a-multimodal-pipeline-for-scanned-archival-documents" class="md-toc-link">
            <p>A Multimodal Pipeline for Scanned Archival Documents</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#introduction" class="md-toc-link">
            <ol>
<li>Introduction</li>
</ol>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#data-and-challenges" class="md-toc-link">
            <ol start="2">
<li>Data and Challenges</li>
</ol>

          </a></div><details style="padding:0;;padding-left:24px;" open="">
        <summary class="md-toc-link-wrapper">
          <a href="#methodology" class="md-toc-link"><ol start="3">
<li>Methodology</li>
</ol>
</a>
          </summary>
        <div>
          <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#ocr-via-multimodal-language-models" class="md-toc-link">
            <p>3.1 OCR via Multimodal Language Models</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#unified-ledger-schema" class="md-toc-link">
            <p>3.2 Unified Ledger Schema</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#confidence-scoring-framework" class="md-toc-link">
            <p>3.3 Confidence Scoring Framework</p>

          </a></div>
        </div>
      </details>
    <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#full-corpus-application" class="md-toc-link">
            <ol start="4">
<li>Full-Corpus Application</li>
</ol>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#confidence-analysis" class="md-toc-link">
            <ol start="5">
<li>Confidence Analysis</li>
</ol>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#discussion" class="md-toc-link">
            <ol start="6">
<li>Discussion</li>
</ol>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#conclusion-and-future-work" class="md-toc-link">
            <ol start="7">
<li>Conclusion and Future Work</li>
</ol>

          </a></div>
        </div>
      </details>
    
</div>
</div>
      <a id="sidebar-toc-btn">≡</a>
    
    
    
    
    
    
<script>

var sidebarTOCBtn = document.getElementById('sidebar-toc-btn')
sidebarTOCBtn.addEventListener('click', function(event) {
  event.stopPropagation()
  if (document.body.hasAttribute('html-show-sidebar-toc')) {
    document.body.removeAttribute('html-show-sidebar-toc')
  } else {
    document.body.setAttribute('html-show-sidebar-toc', true)
  }
})
</script>
      
  
    </body></html>